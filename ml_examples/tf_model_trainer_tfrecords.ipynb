{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and other initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from kubeflow import fairing \n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import imp\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.preprocessing import normalize\n",
    "from google.cloud import storage\n",
    "from tensorflow.io import FixedLenFeature\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append('../utilities/')\n",
    "import modeldb_tf_utilities\n",
    "import evaluation_utilities\n",
    "import model_utilities\n",
    "import from_tfrecords\n",
    "imp.reload(modeldb_tf_utilities)\n",
    "imp.reload(evaluation_utilities)\n",
    "imp.reload(model_utilities)\n",
    "imp.reload(from_tfrecords)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmenon\n",
      "zulilymodeltraining\n"
     ]
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "# Global configs that would be used at all the steps of the notebook.\n",
    "GCP_PROJECT = fairing.backends.gcp.guess_project_name()\n",
    "NAMESPACE = fairing.backends.utils.get_current_k8s_namespace()\n",
    "PROJECT_ID = GCP_PROJECT\n",
    "MODELDB_CLIENT_URL = \"https://modeldb.mlp.ml.gce.z8s.io/\"\n",
    "print(NAMESPACE)\n",
    "print(GCP_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model and Data Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# YAML file containing model data configuration: i.e. Feature names, identification of categorical names etc\n",
    "model_data_config_file_name = \"./../model_configs/text_based_tfrecord_config.yaml\"\n",
    "\n",
    "# Dataset paths\n",
    "data_config = {\n",
    "    #\"training\":'gs://zulilymodeltraining/rmenon/data/tf_records/train/',\n",
    "    \"training\":'gs://zulilymodeltraining/prgupta/test_2',\n",
    "    \"validation\":'gs://zulilymodeltraining/prgupta/test_2',\n",
    "    \"test\":'gs://zulilymodeltraining/prgupta/test_2',\n",
    "}\n",
    "\n",
    "# Path to save trained model and other model-related specs\n",
    "model_data_path_prefix= f\"gs://personalization-tensorflow/models/text_features/\"\n",
    "\n",
    "# Model training parameters\n",
    "model_fit_config = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"initial_lr\": 1e-3,\n",
    "    \"epochs\": 6,\n",
    "    \"shuffle_buffer_size\": 16384,\n",
    "}\n",
    "\n",
    "# Evaluating LTR performance metrics\n",
    "max_rank = 15\n",
    "\n",
    "# Use distributed training across GPUs (only set to True if using >1GPU). Also only efficient for large models.\n",
    "use_distributed_training = False\n",
    "\n",
    "# Use checkpointed model (usually based on lowest validation loss) to generate validation metrics\n",
    "use_checkpointed_model = True\n",
    "\n",
    "# Run locally for testing\n",
    "run_local = True\n",
    "\n",
    "# compression_type_for_tfrecord\n",
    "compression_type = 'GZIP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalizer Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# Parameters related to feature normalizer for the model\n",
    "num_samples_to_train_normalizer = 500 # Set a sample size (in terms of number of batches). If set to None, the entire \"training\" set will be used to train the normalizer.\n",
    "if run_local:\n",
    "    num_samples_to_train_normalizer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model DB Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# Model DB configuration parameters\n",
    "modeldb_config = {\n",
    "    ## Required configs\n",
    "    # These are required configs for a modeldb run. \n",
    "    # Please refer to notes here: https://confluence.zulily.com/display/tech/Notes+about+using+ModelDB if you are updaing the default\n",
    "    # project and experiment name.\n",
    "    \"client_url\": MODELDB_CLIENT_URL,\n",
    "    \"project_name\": 'P13N_Event_Sort_Models_2021',\n",
    "    \"experiment_name\": f\"text-features\",\n",
    "    # Username is mapped into as a ModelDB tag which will help to identiy a run by an user.\n",
    "    \"username\": NAMESPACE,\n",
    "    \n",
    "    ## Optional configs\n",
    "    # If an experiment run name is not specified, then ModelDB will randomly assign a run_name.\n",
    "    \"experiment_run_name\": 'tf_record_format',#'4layer_1024_target_0_458_dataset_v4',\n",
    "    # This parameter is by default true and is required if you are going to run multiple runs with same experiment_run_name.\n",
    "    # This will prevent you from overwritng an experiment_run data and create a new run everytime a pipeline runs.\n",
    "    \"add_random_hash_to_run_name\": 'true'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Internal initializations based on YAML configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# Retrieve model configuration from YAML file.\n",
    "with open(model_data_config_file_name) as file:\n",
    "    model_data_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "# Do some name mappings to make code cleaner\n",
    "feature_names = model_data_config['feature_names']\n",
    "categorical_columns = model_data_config['categorical_columns']\n",
    "categorical_columns_vocabulary_list = model_data_config['categorical_columns_vocabulary_list']\n",
    "numeric_columns_to_norm = model_data_config['numeric_columns_to_norm']\n",
    "vector_features = model_data_config['vector_columns']\n",
    "numeric_columns_remaining = [xx for xx in feature_names if ((xx not in categorical_columns) \\\n",
    "                                                            and (xx not in numeric_columns_to_norm)\\\n",
    "                                                            and (xx not in vector_features))]\n",
    "vector_column_lengths = model_data_config['vector_column_lengths']\n",
    "target_name = model_data_config['target_name']\n",
    "numeric_columns_remaining.remove(target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create/ Load a Feature Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "def google_file_path_exists(path_name):\n",
    "    \"\"\"\n",
    "    Checks if a file path exists in google storage\n",
    "    path_name should be something like 'gs://zulilymodeltraining/rmenon/tf-models-data/normalizer_models/saved_model.pb'\n",
    "    \"\"\"    \n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    interim = path_name.split('//') # Extract gs:\n",
    "    interim = interim[1].split('/') # Extract stuff after gs, 'zulilymodeltraining/rmenon/tf-models-data/normalizer_models/saved_model.pb'\n",
    "    bucket_name = interim[0] # Extract bucket name, 'zulilymodeltraining'\n",
    "    name = ('/').join(interim[1:]) #Create file path excluding bucket name, 'rmenon/tf-models-data/normalizer_models/saved_model.pb'\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    stats = storage.Blob(bucket=bucket, name=name).exists(storage_client)\n",
    "    return(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer training took 1.3728408813476562secs\n"
     ]
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "st = time.time()\n",
    "\n",
    "normalizer_schema = {}\n",
    "for feature in numeric_columns_to_norm:\n",
    "    normalizer_schema[feature] = float\n",
    "    \n",
    "# reate a data generator to run thru the training data for normalizing features\n",
    "data_batches_for_norm = from_tfrecords.from_tfrecords_to_ds(data_config['training'], \\\n",
    "                                                            compression_type = compression_type,\\\n",
    "                                                            schema=normalizer_schema)\\\n",
    "                        .batch(2048)\n",
    "\n",
    "# Pick a random sample if specified\n",
    "if num_samples_to_train_normalizer is not None:\n",
    "    data_batches_for_norm = data_batches_for_norm.take(int(num_samples_to_train_normalizer))\n",
    "\n",
    "# Stack features: Change from dictionary format to a a stacked tensor array\n",
    "def stack_features(features):\n",
    "    return tf.stack(list(features.values()), axis=1)\n",
    "data_batches_for_norm_stacked = data_batches_for_norm.map(stack_features)\n",
    "\n",
    "\n",
    "# Train the normalizer \n",
    "if use_distributed_training:\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        feature_normalizer = preprocessing.Normalization()\n",
    "        feature_normalizer.adapt(data_batches_for_norm_stacked)\n",
    "else:\n",
    "    feature_normalizer = preprocessing.Normalization()\n",
    "    feature_normalizer.adapt(data_batches_for_norm_stacked)\n",
    "print('Normalizer training took {}secs'.format(time.time() - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.preprocessing.normalization.Normalization at 0x7f47fc1a1310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# Model-DB logging functions\n",
    "def log_model_attributes(modeldb_expt_run):\n",
    "    \"\"\"\n",
    "    Capturing Model attributes before starting training in ModelDB.\n",
    "    \"\"\"\n",
    "    modeldb_expt_run.log_hyperparameters(model_fit_config)\n",
    "    modeldb_expt_run.log_attributes(data_config)\n",
    "    modeldb_expt_run.log_attributes(model_data_config)\n",
    "\n",
    "    \n",
    "def log_model_metrics(modeldb_expt_run, model, model_save_path, model_checkpoint_path, test_ds = None):\n",
    "    \"\"\"\n",
    "    Capturing Model metrics at the end of training in ModelDB.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log the paths where the model and related data were saved\n",
    "    modeldb_expt_run.log_artifact_path('other_model_related_data_path', model_data_path_prefix)\n",
    "    modeldb_expt_run.log_artifact_path('model_save_path', model_save_path)\n",
    "    modeldb_expt_run.log_artifact_path('model_checkpoint_path', model_checkpoint_path)\n",
    "    \n",
    "    # Log accuracy of the supplied data set (if supplied)\n",
    "    if test_ds is not None:\n",
    "        loss, accuracy, precision, recall = model.evaluate(test_ds)        \n",
    "        modeldb_expt_run.log_metric('loss_', loss)\n",
    "        modeldb_expt_run.log_metric('accuracy', accuracy)\n",
    "        modeldb_expt_run.log_metric('precision', precision)\n",
    "        modeldb_expt_run.log_metric('recall', recall)\n",
    "        \n",
    "\n",
    "def log_model_summary(modeldb_expt_run, model):\n",
    "    \"\"\"\n",
    "    Log the structure of the Model\n",
    "    \"\"\"\n",
    "    stringlist = []\n",
    "    # Only store the last sequential layer\n",
    "    model.get_layer(index=-1).summary(print_fn=lambda x: stringlist.append(x))\n",
    "    short_model_summary = \"\\n\".join(stringlist)    \n",
    "    \n",
    "    if os.path.exists('/tmp/model/'):        \n",
    "        shutil.rmtree('/tmp/model')\n",
    "    os.mkdir('/tmp/model')\n",
    "\n",
    "    with open('/tmp/model/model.txt', 'w') as f:\n",
    "        f.write(short_model_summary)\n",
    "    f.close()\n",
    "    modeldb_expt_run.log_artifact('Model_Summary', '/tmp/model/model.txt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# Target variable mapping function\n",
    "def parse_label_from_data(data):\n",
    "    \"\"\"\n",
    "    Function to map the data parsed in order to generate the labels\n",
    "    \"\"\"\n",
    "    labels = data.pop(target_name)\n",
    "    \n",
    "    label_0_values = tf.constant(['0'], dtype=tf.dtypes.string)    \n",
    "    labels = tf.reshape(labels, [-1, 1])\n",
    "    labels_converted = tf.where(tf.reduce_any(tf.equal(labels, label_0_values), axis=1), \n",
    "                              tf.constant(0, dtype=tf.dtypes.int64), \n",
    "                              tf.constant(1, dtype=tf.dtypes.int64)) \n",
    "    return data, labels_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "# Get training, test and validation data generators\n",
    "training_data = from_tfrecords.from_tfrecords_to_ds(data_config['training'], compression_type = compression_type,) \\\n",
    "        .map(parse_label_from_data, num_parallel_calls=AUTOTUNE) \\\n",
    "        .shuffle(model_fit_config['shuffle_buffer_size']).batch(model_fit_config['batch_size'])\n",
    "training_data = training_data.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "validation_data = from_tfrecords.from_tfrecords_to_ds(data_config['validation'], compression_type = compression_type,) \\\n",
    "        .map(parse_label_from_data, num_parallel_calls=AUTOTUNE) \\\n",
    "        .batch(model_fit_config['batch_size'])\n",
    "validation_data = validation_data.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_data = from_tfrecords.from_tfrecords_to_ds(data_config['test'], compression_type = compression_type,) \\\n",
    "        .map(parse_label_from_data, num_parallel_calls=AUTOTUNE) \\\n",
    "        .batch(model_fit_config['batch_size'])\n",
    "test_data = test_data.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "if run_local:\n",
    "    # For testing purposes: Selects just 1 batch of data for training, validation and test\n",
    "    training_data = training_data.take(1)\n",
    "    validation_data = validation_data.take(1)\n",
    "    test_data = test_data.take(1)\n",
    "else:\n",
    "    # Using just 1/10th dataset for training and validation\n",
    "    #training_data = training_data.shard(10, 1) \n",
    "    validation_data = validation_data.shard(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection successfully established\n",
      "got existing Project: P13N_Event_Sort_Models_2021\n",
      "got existing Experiment: text-features\n",
      "created new ExperimentRun: tf_record_format_589xap8a\n",
      "upload complete (Model_Summary)\n"
     ]
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "initial_lr = model_fit_config['initial_lr']\n",
    "num_epochs = model_fit_config['epochs']\n",
    "\n",
    "# Create Model-DB Instance\n",
    "modeldb_expt_run = modeldb_tf_utilities.create_modeldb_experiment_run(modeldb_config)\n",
    "\n",
    "# Get callbacks and save paths\n",
    "model_data_path_prefix = os.path.join(model_data_path_prefix, modeldb_expt_run.name)\n",
    "callbacks = modeldb_tf_utilities.get_tf_callbacks(modeldb_expt_run, model_data_path_prefix)\n",
    "\n",
    "# Save some attributes before training starts\n",
    "log_model_attributes(modeldb_expt_run)\n",
    "\n",
    "# Define model \n",
    "#loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "loss=tf.keras.losses.MeanSquaredError()\n",
    "optimizer=tf.optimizers.Adam(learning_rate=initial_lr)\n",
    "\n",
    "# Create a distribution strategy to run on multiple GPUs\n",
    "if use_distributed_training:\n",
    "    with mirrored_strategy.scope():\n",
    "        sort_model = model_utilities.get_tfrecord_sort_model(feature_normalizer, \n",
    "                                                       numeric_columns_to_norm, \n",
    "                                                       numeric_columns_remaining, \n",
    "                                                       categorical_columns,\n",
    "                                                       categorical_columns_vocabulary_list,\n",
    "                                                       vector_features,\n",
    "                                                        vector_column_lengths)\n",
    "        sort_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "else:\n",
    "    sort_model = model_utilities.get_tfrecord_sort_model(feature_normalizer,\n",
    "                                                   numeric_columns_to_norm, \n",
    "                                                   numeric_columns_remaining, \n",
    "                                                   categorical_columns,\n",
    "                                                   categorical_columns_vocabulary_list,\n",
    "                                                    vector_features,\n",
    "                                                    vector_column_lengths)\n",
    "    sort_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "log_model_summary(modeldb_expt_run, sort_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "estimated_demand (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "projected_demand (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "demand_to_date_norm (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "order_ct_to_date_norm (InputLay [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4)            0           estimated_demand[0][0]           \n",
      "                                                                 projected_demand[0][0]           \n",
      "                                                                 demand_to_date_norm[0][0]        \n",
      "                                                                 order_ct_to_date_norm[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_channel (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age_segment (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conversion_rate_impression (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conversion_rate_pageview (Input [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cust_maternity_views (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cust_msrp_iqr_ppt (InputLayer)  [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cust_msrp_median_ppt (InputLaye [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cust_price_iqr_ppt (InputLayer) [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cust_price_median_ppt (InputLay [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "customer_age (InputLayer)       [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "customer_gender (InputLayer)    [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_age (InputLayer)          [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_gender (InputLayer)       [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_top_ppt (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "join_channel (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msrp_iqr (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msrp_median (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "non_branded (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price_iqr (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price_median (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subjectline_eligible (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_embd_cart_adds (InputLayer [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_embd_event (InputLayer)    [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_embd_style_views (InputLay [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 4)            9           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_features (DenseFeatures)  (None, 450)          0           activation_channel[0][0]         \n",
      "                                                                 age_segment[0][0]                \n",
      "                                                                 conversion_rate_impression[0][0] \n",
      "                                                                 conversion_rate_pageview[0][0]   \n",
      "                                                                 cust_maternity_views[0][0]       \n",
      "                                                                 cust_msrp_iqr_ppt[0][0]          \n",
      "                                                                 cust_msrp_median_ppt[0][0]       \n",
      "                                                                 cust_price_iqr_ppt[0][0]         \n",
      "                                                                 cust_price_median_ppt[0][0]      \n",
      "                                                                 customer_age[0][0]               \n",
      "                                                                 customer_gender[0][0]            \n",
      "                                                                 event_age[0][0]                  \n",
      "                                                                 event_gender[0][0]               \n",
      "                                                                 event_top_ppt[0][0]              \n",
      "                                                                 join_channel[0][0]               \n",
      "                                                                 msrp_iqr[0][0]                   \n",
      "                                                                 msrp_median[0][0]                \n",
      "                                                                 non_branded[0][0]                \n",
      "                                                                 price_iqr[0][0]                  \n",
      "                                                                 price_median[0][0]               \n",
      "                                                                 subjectline_eligible[0][0]       \n",
      "                                                                 text_embd_cart_adds[0][0]        \n",
      "                                                                 text_embd_event[0][0]            \n",
      "                                                                 text_embd_style_views[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 454)          0           normalization[0][0]              \n",
      "                                                                 dense_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 1)            1056513     concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,056,522\n",
      "Trainable params: 1,056,513\n",
      "Non-trainable params: 9\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sort_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_iqr_ppt'), name='cust_msrp_iqr_ppt', description=\"created by layer 'cust_msrp_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:588: UserWarning: Input dict contained keys ['customer_id', 'event_id', 'event_position', 'new_today', 'send_date'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n",
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_iqr_ppt'), name='cust_msrp_iqr_ppt', description=\"created by layer 'cust_msrp_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_median_ppt'), name='cust_msrp_median_ppt', description=\"created by layer 'cust_msrp_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_median_ppt'), name='cust_msrp_median_ppt', description=\"created by layer 'cust_msrp_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_iqr_ppt'), name='cust_price_iqr_ppt', description=\"created by layer 'cust_price_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_iqr_ppt'), name='cust_price_iqr_ppt', description=\"created by layer 'cust_price_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_median_ppt'), name='cust_price_median_ppt', description=\"created by layer 'cust_price_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_median_ppt'), name='cust_price_median_ppt', description=\"created by layer 'cust_price_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='customer_age'), name='customer_age', description=\"created by layer 'customer_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='customer_age'), name='customer_age', description=\"created by layer 'customer_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='customer_gender'), name='customer_gender', description=\"created by layer 'customer_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='customer_gender'), name='customer_gender', description=\"created by layer 'customer_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='event_age'), name='event_age', description=\"created by layer 'event_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='event_age'), name='event_age', description=\"created by layer 'event_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='event_gender'), name='event_gender', description=\"created by layer 'event_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='event_gender'), name='event_gender', description=\"created by layer 'event_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_cart_adds'), name='text_embd_cart_adds', description=\"created by layer 'text_embd_cart_adds'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_cart_adds'), name='text_embd_cart_adds', description=\"created by layer 'text_embd_cart_adds'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_event'), name='text_embd_event', description=\"created by layer 'text_embd_event'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_event'), name='text_embd_event', description=\"created by layer 'text_embd_event'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_style_views'), name='text_embd_style_views', description=\"created by layer 'text_embd_style_views'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:51 functional:632] Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_style_views'), name='text_embd_style_views', description=\"created by layer 'text_embd_style_views'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_iqr_ppt'), name='cust_msrp_iqr_ppt', description=\"created by layer 'cust_msrp_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_iqr_ppt'), name='cust_msrp_iqr_ppt', description=\"created by layer 'cust_msrp_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_median_ppt'), name='cust_msrp_median_ppt', description=\"created by layer 'cust_msrp_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_msrp_median_ppt'), name='cust_msrp_median_ppt', description=\"created by layer 'cust_msrp_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_iqr_ppt'), name='cust_price_iqr_ppt', description=\"created by layer 'cust_price_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_iqr_ppt'), name='cust_price_iqr_ppt', description=\"created by layer 'cust_price_iqr_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_median_ppt'), name='cust_price_median_ppt', description=\"created by layer 'cust_price_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='cust_price_median_ppt'), name='cust_price_median_ppt', description=\"created by layer 'cust_price_median_ppt'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='customer_age'), name='customer_age', description=\"created by layer 'customer_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='customer_age'), name='customer_age', description=\"created by layer 'customer_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='customer_gender'), name='customer_gender', description=\"created by layer 'customer_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='customer_gender'), name='customer_gender', description=\"created by layer 'customer_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='event_age'), name='event_age', description=\"created by layer 'event_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='event_age'), name='event_age', description=\"created by layer 'event_age'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='event_gender'), name='event_gender', description=\"created by layer 'event_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='event_gender'), name='event_gender', description=\"created by layer 'event_gender'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_cart_adds'), name='text_embd_cart_adds', description=\"created by layer 'text_embd_cart_adds'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_cart_adds'), name='text_embd_cart_adds', description=\"created by layer 'text_embd_cart_adds'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_event'), name='text_embd_event', description=\"created by layer 'text_embd_event'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_event'), name='text_embd_event', description=\"created by layer 'text_embd_event'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_style_views'), name='text_embd_style_views', description=\"created by layer 'text_embd_style_views'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 211209 04:23:52 functional:632] Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='text_embd_style_views'), name='text_embd_style_views', description=\"created by layer 'text_embd_style_views'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Key: text_embd_style_views.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3437]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-72da2bb14074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#cached_validation_ds = validation_data.cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Log time taken to fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodeldb_expt_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_fit_run_duration_in_secs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Key: text_embd_style_views.  Can't parse serialized Example.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3437]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "# Start the training process\n",
    "try:\n",
    "    start_time = time.time()  \n",
    "    #cached_ds = training_data.cache()\n",
    "    #cached_validation_ds = validation_data.cache()\n",
    "    # Fit the model\n",
    "    model_history = sort_model.fit(training_data, validation_data=validation_data, epochs=num_epochs, callbacks=callbacks)\n",
    "    # Log time taken to fit model\n",
    "    modeldb_expt_run.log_metric('model_fit_run_duration_in_secs', (time.time() - start_time))            \n",
    "    # Save Model\n",
    "    model_save_path = os.path.join(model_data_path_prefix, 'saved_model/')\n",
    "    sort_model.save(model_save_path)\n",
    "    # But reload model from checkpoint (lowest validation loss) to generate validation performance\n",
    "    model_checkpoint_path = os.path.join(model_data_path_prefix, 'checkpoints/')\n",
    "    if use_checkpointed_model:\n",
    "        # But reload model from checkpoint (lowest validation loss) to generate validation performance        \n",
    "        sort_model.load_weights(model_checkpoint_path)    \n",
    "    # Log other metrics from model including validation data performance\n",
    "    log_model_metrics(modeldb_expt_run, sort_model, model_save_path, model_checkpoint_path, validation_data)\n",
    "    modeldb_expt_run.log_tag('success')\n",
    "except:\n",
    "    modeldb_expt_run.log_tag('failed_run')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate Performance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:588: UserWarning: Input dict contained keys ['customer_id', 'event_id', 'event_position', 'new_today', 'send_date'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Time taken for generating labels is 2.773676633834839secs\n"
     ]
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "st = time.time()\n",
    "\n",
    "# Get predicted labels for validation data\n",
    "pred_indices_raw = sort_model.predict(validation_data, verbose=1)\n",
    "pred_indices = (pred_indices_raw > 0.5)\n",
    "\n",
    "# Get true labels for test data\n",
    "iterator = validation_data.as_numpy_iterator()\n",
    "true_labels = np.array([])\n",
    "for x in iterator:\n",
    "    true_labels = np.append(true_labels, x[-1])\n",
    "print(\"Time taken for generating labels is {}secs\".format(time.time() - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here\n"
     ]
    }
   ],
   "source": [
    "print('I am here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.65      0.86      0.74      1011\n",
      "     class 1       0.80      0.56      0.65      1037\n",
      "\n",
      "    accuracy                           0.70      2048\n",
      "   macro avg       0.73      0.71      0.70      2048\n",
      "weighted avg       0.73      0.70      0.70      2048\n",
      "\n",
      "upload complete (ROC)\n",
      "upload complete (PR)\n",
      "upload complete (confusion_matrix)\n",
      "upload complete (confusion_matrix_normalized)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "# Making sure directory is removed if already exists\n",
    "if os.path.exists('/tmp/plots'):        \n",
    "    shutil.rmtree('/tmp/plots')\n",
    "os.mkdir('/tmp/plots')\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "\n",
    "# Print Some Performance Metrics\n",
    "print(classification_report(true_labels, pred_indices, target_names = target_names, zero_division = 0))\n",
    "cr = classification_report(true_labels, pred_indices, target_names = target_names, zero_division=0, output_dict = True)\n",
    "class_0_recall = np.around(cr['class 0']['recall'], decimals=5)\n",
    "class_1_recall = np.around(cr['class 1']['recall'], decimals=5)\n",
    "modeldb_expt_run.log_metrics({'Recall_Class_0': class_0_recall, 'Recall_Class_1': class_1_recall, })\n",
    "\n",
    "\n",
    "# Create ROC curve\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, pred_indices_raw)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.savefig('/tmp/plots/roc.png')\n",
    "modeldb_expt_run.log_artifact('ROC', '/tmp/plots/roc.png')\n",
    "\n",
    "# Create PR curve\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "precision, recall, thresholds = precision_recall_curve(true_labels, pred_indices_raw)\n",
    "plt.plot(recall, precision)\n",
    "plt.title('PR curve')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.savefig('/tmp/plots/pr.png')\n",
    "modeldb_expt_run.log_artifact('PR', '/tmp/plots/pr.png')\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_indices)\n",
    "cm_df = pd.DataFrame(cm, index = target_names, columns = target_names)\n",
    "cm_normalize_df = pd.DataFrame(normalize(cm, 'l1', axis = 1), index = target_names, columns = target_names)\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "svm = sns.heatmap(cm_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "figure = svm.get_figure()    \n",
    "figure.savefig('/tmp/plots/cm.png')\n",
    "\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "svm = sns.heatmap(cm_normalize_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "figure = svm.get_figure()    \n",
    "figure.savefig('/tmp/plots/cm_norm.png')\n",
    "\n",
    "# Saving confusion_matrix\n",
    "modeldb_expt_run.log_artifact('confusion_matrix', '/tmp/plots/cm.png')\n",
    "modeldb_expt_run.log_artifact('confusion_matrix_normalized', '/tmp/plots/cm_norm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:588: UserWarning: Input dict contained keys ['customer_id', 'event_id', 'event_position', 'new_today', 'send_date'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast int64 to string is not supported\n\t [[node model_12/Cast (defined at <ipython-input-207-dfdef1f1ce28>:9) ]] [Op:__inference_predict_function_81440]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-dfdef1f1ce28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get predictions from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process took {}secs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast int64 to string is not supported\n\t [[node model_12/Cast (defined at <ipython-input-207-dfdef1f1ce28>:9) ]] [Op:__inference_predict_function_81440]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "# fairing:include-cell\n",
    "# Get LTR Metrics on a test-data set\n",
    "if os.path.exists('/tmp/data'):        \n",
    "    shutil.rmtree('/tmp/data')\n",
    "os.mkdir('/tmp/data')\n",
    "\n",
    "# Get predictions from the model\n",
    "st = time.time()\n",
    "model_predictions = sort_model.predict(test_data, verbose=1)\n",
    "print('Process took {}secs'.format(time.time() - st))\n",
    "\n",
    "# Construct a pandas dataframe with scores and target\n",
    "st = time.time()\n",
    "model_results_df = pd.DataFrame()\n",
    "for f, t in test_data:\n",
    "    temp = pd.DataFrame()\n",
    "    temp[target_name] = t\n",
    "    temp['customer_id'] = f['customer_id']\n",
    "    model_results_df = model_results_df.append(temp)\n",
    "print('Process took {}secs'.format(time.time() - st))\n",
    "model_results_df['predicted'] = model_predictions\n",
    "prediction_column = 'predicted'\n",
    "\n",
    "# Call the function to evaluate LTR metrics\n",
    "model_metrics = pd.DataFrame()\n",
    "model_hit_rate, model_ndcg = evaluation_utilities.get_ltr_metrics(model_results_df, \n",
    "                                                                         max_rank, \n",
    "                                                                         target_name, \n",
    "                                                                         prediction_column)\n",
    "\n",
    "model_metrics['hit_rate'] = model_hit_rate\n",
    "model_metrics['ndcg'] = model_ndcg\n",
    "\n",
    "modeldb_expt_run.log_metrics({'HR_10': model_hit_rate[9], 'NDCG_10': model_ndcg[9]})\n",
    "model_metrics.to_csv(f'/tmp/data/{modeldb_expt_run.name}.csv')\n",
    "modeldb_expt_run.log_artifact('LTRMetrics', f'/tmp/data/{modeldb_expt_run.name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "modeldb_expt_run.log_metric('experiment_run_duration_in_secs', (time.time() - start_time))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run below cells to get information about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_sort_model = get_sort_model(feature_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_sort_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort_model.get_layer(index=-1).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort_model.get_layer(index=-1).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Below to evaluate model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sort_model = get_sort_model(numeric_preprocessor=feature_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'gs://personalization-tensorflow/models/text_features/4layer_1024_target_0_458_correct_age_gender_jqgdjbdo'\n",
    "checkpoint_path = os.path.join(model_save_path, 'checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sort_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the model\n",
    "st = time.time()\n",
    "model_predictions = a_sort_model.predict(test_data, verbose = 1)\n",
    "print('Process took {}secs'.format(time.time() - st))\n",
    "\n",
    "# Construct a pandas dataframe with scores and target\n",
    "st = time.time()\n",
    "model_results_df = pd.DataFrame()\n",
    "for f, t in test_data:\n",
    "    temp = pd.DataFrame()\n",
    "    temp[target_name] = t\n",
    "    temp['customer_id'] = f['customer_id']\n",
    "    model_results_df = model_results_df.append(temp)\n",
    "print('Process took {}secs'.format(time.time() - st))\n",
    "model_results_df['predicted'] = model_predictions\n",
    "prediction_column = 'predicted'\n",
    "\n",
    "# Call the function to evaluate LTR metrics\n",
    "model_metrics = pd.DataFrame()\n",
    "model_hit_rate, model_ndcg = evaluation_utilities.get_ltr_metrics(model_results_df, \n",
    "                                                                         max_rank, \n",
    "                                                                         target_name, \n",
    "                                                                         prediction_column)\n",
    "\n",
    "model_metrics['hit_rate'] = model_hit_rate\n",
    "model_metrics['ndcg'] = model_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare with BS Results\n",
    "file_path_to_bs_results = \"bs_results_on_test_test_v2.csv\"\n",
    "bs_model_metrics = pd.read_csv(file_path_to_bs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(1,max_rank), model_metrics['hit_rate'], '*-', label='Text based model')\n",
    "plt.plot(np.arange(1,max_rank), bs_model_metrics['hit_rate'], '*-', label='Estimated-demand based model')\n",
    "plt.ylabel('HR@K')\n",
    "plt.xlabel('K')\n",
    "plt.grid(b=True)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1,max_rank), model_metrics['ndcg'], '*-', label='Text based model')\n",
    "plt.plot(np.arange(1,max_rank), bs_model_metrics['ndcg'], '*-', label='Estimated-demand based model')\n",
    "plt.ylabel('NDCG@K')\n",
    "plt.xlabel('K')\n",
    "plt.grid(b=True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
