{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Model training script for Kubeflow pipeline and Katib\n",
    "Uses TFRecords created using Spark\n",
    "\n",
    "Adapted from https://gitlab.corp.zulily.com/personalization/user-guides/kubeflow-tensorflow/-/blob/master/model_train_tf_records.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get project-ID and collect Python module package components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: zulilymodeltraining\n",
      "Namespace: rmenon\n"
     ]
    }
   ],
   "source": [
    "# Get your GCP project id from gcloud\n",
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID:\", PROJECT_ID)\n",
    "NAMESPACE =  'rmenon'#tf_job_utils.get_default_target_namespace() - not working\n",
    "print(\"Namespace:\", NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module path is:  gs://zulilymodeltraining/rmenon/p13n-tf-trainer_module\n"
     ]
    }
   ],
   "source": [
    "# Path used to save this python trainer module\n",
    "MODULE_PATH = f\"gs://{PROJECT_ID}/{NAMESPACE}/p13n-tf-trainer_module\"\n",
    "print('Module path is: ', MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "# Add requirements information\n",
    "requirements = \"tensorflow==2.5.0\\ntensorflow_io==0.19.1\\nverta==0.17.6\\ngoogle-cloud-storage==1.38.0\"\n",
    "! echo \"$requirements\" > custom/requirements.txt\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nwith open('requirements.txt') as f:\\n    REQUIRES = f.readlines()\\n\\nsetuptools.setup(\\n\\n    name='trainer',\\n\\n    install_requires=REQUIRES,\\n\\n    packages=setuptools.find_packages(),\\n\\n    package_data = {'': ['*.yaml']})\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Flowers image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder and adding utils and relavent files to the trainer director\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py\n",
    "! cp ../utilities/common_utilities.py custom/trainer/\n",
    "! cp ../utilities/modeldb_tf_utilities.py custom/trainer/\n",
    "! cp ../utilities/model_utilities.py custom/trainer/\n",
    "! cp ../utilities/tf_records_utils.py custom/trainer/\n",
    "! cp ../model_configs/text_based_tfrecord_config.yaml custom/trainer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import logging\n",
    "import yaml\n",
    "import shutil\n",
    "from google.cloud import storage\n",
    "from tensorflow.io import FixedLenFeature\n",
    "\n",
    "\n",
    "# This will make sure that we are able to import utils and from_tfrcords as they ll be added to pythonpath while executing this script\n",
    "file_dir = os.path.dirname(__file__)\n",
    "sys.path.append(file_dir)\n",
    "print(file_dir)\n",
    "\n",
    "import modeldb_tf_utilities\n",
    "import model_utilities\n",
    "import tf_records_utils\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model and Data Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "# YAML file containing model data configuration: i.e. Feature names, identification of categorical names etc\n",
    "model_data_config_file_name = os.path.join(file_dir, \"text_based_tfrecord_config.yaml\")\n",
    "print(model_data_config_file_name)\n",
    "\n",
    "# Dataset paths\n",
    "data_config = {\n",
    "    \"training\":'gs://zulilymodeltraining/rmenon/data/tfrecords/version_8/train/',\n",
    "    \"validation\":'gs://zulilymodeltraining/rmenon/data/tfrecords/version_8/valid/',\n",
    "    \"test\":'gs://zulilymodeltraining/rmenon/data/tfrecords/version_8/test/',\n",
    "}\n",
    "\n",
    "# Path to save trained model and other model-related specs\n",
    "model_data_path_prefix= f\"gs://personalization-tensorflow/models/text_features/\"\n",
    "\n",
    "# Model training parameters\n",
    "model_fit_config = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"initial_lr\": 1e-3,\n",
    "    \"epochs\": 6,\n",
    "    \"shuffle_buffer_size\": 16384,\n",
    "}\n",
    "\n",
    "# Evaluating LTR performance metrics\n",
    "max_rank = 15\n",
    "\n",
    "# Use distributed training across GPUs (only set to True if using >1GPU). Also only efficient for large models.\n",
    "use_distributed_training = False\n",
    "\n",
    "# Use checkpointed model (usually based on lowest validation loss) to generate validation metrics\n",
    "use_checkpointed_model = True\n",
    "\n",
    "# Run locally for testing\n",
    "run_local = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalizer Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "# Parameters related to feature normalizer for the model\n",
    "num_samples_to_train_normalizer = 500 # Set a sample size (in terms of number of batches). If set to None, the entire \"training\" set will be used to train the normalizer.\n",
    "if run_local:\n",
    "    num_samples_to_train_normalizer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model DB Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "# Model DB configuration parameters\n",
    "modeldb_config = {\n",
    "    ## Required configs\n",
    "    # These are required configs for a modeldb run. \n",
    "    # Please refer to notes here: https://confluence.zulily.com/display/tech/Notes+about+using+ModelDB if you are updaing the default\n",
    "    # project and experiment name.\n",
    "    \"client_url\": \"https://modeldb.mlp.ml.gce.z8s.io/\",\n",
    "    \"project_name\": 'P13N_Event_Sort_Models_2021',\n",
    "    \n",
    "    # This parameter is by default true and is required if you are going to run multiple runs with same experiment_run_name.\n",
    "    # This will prevent you from overwritng an experiment_run data and create a new run everytime a pipeline runs.\n",
    "    \"add_random_hash_to_run_name\": 'true'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment configuration parameters with command line arguments - if provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"TF.Keras Daily Email Model\")\n",
    "parser.add_argument(\"--module-path\", dest=\"module_path\", default=\"\", type=str, help=\"GCS location of the training module.\")\n",
    "parser.add_argument(\"--namespace\", dest=\"namespace\", type=str, help=\"User namespace.\")\n",
    "\n",
    "# training hyperparameters\n",
    "parser.add_argument(\"--lr\", dest=\"initial_lr\", default=model_fit_config['initial_lr'], type=float, help=\"Learning rate.\")\n",
    "parser.add_argument(\"--batch-size\", dest=\"batch_size\", default=model_fit_config['batch_size'], type=int, help=\"mini-batch size\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--modeldb-experiment-name\", dest=\"modeldb_experiment_name\", type=str, help=\"ModelDB Experiment Name\")\n",
    "parser.add_argument(\n",
    "    \"--modeldb-experiment-run-name\", dest=\"modeldb_experiment_run_name\", type=str,\n",
    "    help=\"ModelDB Experiment Run Name. If an experiment run name is not specified, then ModelDB will randomly assign a run_name.\")    \n",
    "args = parser.parse_args()\n",
    "\n",
    "modeldb_config['username'] = args.namespace\n",
    "modeldb_config['experiment_name'] = args.modeldb_experiment_name\n",
    "modeldb_config['experiment_run_name'] = args.modeldb_experiment_run_name\n",
    "model_fit_config['batch_size']= args.batch_size\n",
    "model_fit_config['initial_lr']= args.initial_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Internal initializations based on YAML configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "# Retrieve model configuration from YAML file.\n",
    "with open(model_data_config_file_name) as file:\n",
    "    model_data_config = yaml.load(file, Loader=yaml.SafeLoader)\n",
    "# Do some name mappings to make code cleaner\n",
    "feature_names = model_data_config['feature_names']\n",
    "categorical_columns = model_data_config['categorical_columns']\n",
    "categorical_columns_vocabulary_list = model_data_config['categorical_columns_vocabulary_list']\n",
    "numeric_columns_to_norm = model_data_config['numeric_columns_to_norm']\n",
    "vector_features = model_data_config['vector_columns']\n",
    "identifier_columns = model_data_config['identifier_columns']\n",
    "numeric_columns_remaining = [xx for xx in feature_names if ((xx not in categorical_columns) \\\n",
    "                                                            and (xx not in numeric_columns_to_norm)\\\n",
    "                                                            and (xx not in vector_features))]\n",
    "vector_column_lengths = model_data_config['vector_column_lengths']\n",
    "target_name = model_data_config['target_name']\n",
    "numeric_columns_remaining.remove(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "# Build TF Structure\n",
    "tf_feature_descriptions = dict()\n",
    "# Assume that identifier columns are first\n",
    "for column in identifier_columns:\n",
    "    tf_feature_descriptions[column] = tf.io.FixedLenFeature([], tf.string)\n",
    "for column in feature_names:\n",
    "    if column == target_name:\n",
    "        tf_feature_descriptions[column] = tf.io.FixedLenFeature([], tf.int64)\n",
    "    else:\n",
    "        if column in categorical_columns:\n",
    "            if column in vector_features:\n",
    "                tf_feature_descriptions[column] = tf.io.FixedLenFeature([vector_column_lengths[column]], tf.string)\n",
    "            else:\n",
    "                tf_feature_descriptions[column] = tf.io.FixedLenFeature([], tf.string)  \n",
    "        else:\n",
    "            if column in vector_features:\n",
    "                tf_feature_descriptions[column] = tf.io.FixedLenFeature([vector_column_lengths[column]], tf.float32)\n",
    "            else:\n",
    "                tf_feature_descriptions[column] = tf.io.FixedLenFeature([], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create/ Load a Feature Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "def parse_tf_records_norm(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, normalizer_tf_feature_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "normalizer_tf_feature_descriptions = {}\n",
    "for column in numeric_columns_to_norm:    \n",
    "    normalizer_tf_feature_descriptions[column] = tf.io.FixedLenFeature([], tf.float32)\n",
    "    \n",
    "# reate a data generator to run thru the training data for normalizing features\n",
    "data_batches_for_norm = tf_records_utils.get_tf_record_ds(data_config['training'])\\\n",
    "                        .map(parse_tf_records_norm, num_parallel_calls=AUTOTUNE) \\\n",
    "                        .batch(2048)\n",
    "\n",
    "# Pick a random sample if specified\n",
    "if num_samples_to_train_normalizer is not None:\n",
    "    data_batches_for_norm = data_batches_for_norm.take(int(num_samples_to_train_normalizer))\n",
    "\n",
    "# Stack features: Change from dictionary format to a a stacked tensor array\n",
    "def stack_features(features):\n",
    "    return tf.stack(list(features.values()), axis=1)\n",
    "data_batches_for_norm_stacked = data_batches_for_norm.map(stack_features)\n",
    "\n",
    "\n",
    "# Train the normalizer \n",
    "if use_distributed_training:\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        feature_normalizer = preprocessing.Normalization()\n",
    "        feature_normalizer.adapt(data_batches_for_norm_stacked)\n",
    "else:\n",
    "    feature_normalizer = preprocessing.Normalization()\n",
    "    feature_normalizer.adapt(data_batches_for_norm_stacked)\n",
    "print('Normalizer training took {}secs'.format(time.time() - st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "# Model-DB logging functions\n",
    "def log_model_attributes(modeldb_expt_run):\n",
    "    \"\"\"\n",
    "    Capturing Model attributes before starting training in ModelDB.\n",
    "    \"\"\"\n",
    "    modeldb_expt_run.log_hyperparameters(model_fit_config)\n",
    "    modeldb_expt_run.log_attributes(data_config)\n",
    "    modeldb_expt_run.log_attributes(model_data_config)\n",
    "\n",
    "    \n",
    "def log_model_metrics(modeldb_expt_run, model, model_save_path, model_checkpoint_path, test_ds = None):\n",
    "    \"\"\"\n",
    "    Capturing Model metrics at the end of training in ModelDB.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log the paths where the model and related data were saved\n",
    "    modeldb_expt_run.log_artifact_path('other_model_related_data_path', model_data_path_prefix)\n",
    "    modeldb_expt_run.log_artifact_path('model_save_path', model_save_path)\n",
    "    modeldb_expt_run.log_artifact_path('model_checkpoint_path', model_checkpoint_path)\n",
    "    \n",
    "    # Log accuracy of the supplied data set (if supplied)\n",
    "    if test_ds is not None:\n",
    "        loss, accuracy, precision, recall = model.evaluate(test_ds)        \n",
    "        modeldb_expt_run.log_metric('loss_', loss)\n",
    "        modeldb_expt_run.log_metric('accuracy', accuracy)\n",
    "        modeldb_expt_run.log_metric('precision', precision)\n",
    "        modeldb_expt_run.log_metric('recall', recall)\n",
    "        # Printing the result is important as katib parses this output to report metric\n",
    "        print(\"\\naccuracy={}\".format(accuracy))\n",
    "        print(\"\\nloss={}\".format(loss))\n",
    "        \n",
    "\n",
    "def log_model_summary(modeldb_expt_run, model):\n",
    "    \"\"\"\n",
    "    Log the structure of the Model\n",
    "    \"\"\"\n",
    "    stringlist = []\n",
    "    # Only store the last sequential layer\n",
    "    model.get_layer(index=-1).summary(print_fn=lambda x: stringlist.append(x))\n",
    "    short_model_summary = \"\\n\".join(stringlist)    \n",
    "    \n",
    "    if os.path.exists('/tmp/model/'):        \n",
    "        shutil.rmtree('/tmp/model')\n",
    "    os.mkdir('/tmp/model')\n",
    "\n",
    "    with open('/tmp/model/model.txt', 'w') as f:\n",
    "        f.write(short_model_summary)\n",
    "    f.close()\n",
    "    modeldb_expt_run.log_artifact('Model_Summary', '/tmp/model/model.txt')    \n",
    "    \n",
    "def parse_tf_records(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, tf_feature_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "# Target variable mapping function\n",
    "def parse_label_from_data(data):\n",
    "    \"\"\"\n",
    "    Function to map the data parsed in order to generate the labels\n",
    "    \"\"\"\n",
    "    labels = data.pop(target_name)\n",
    "    \n",
    "    label_0_values = tf.constant([0], dtype=tf.dtypes.int64)    \n",
    "    labels = tf.reshape(labels, [-1, 1])\n",
    "    labels_converted = tf.where(tf.reduce_any(tf.equal(labels, label_0_values), axis=1), \n",
    "                              tf.constant(0, dtype=tf.dtypes.int64), \n",
    "                              tf.constant(1, dtype=tf.dtypes.int64)) \n",
    "    return data, labels_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "# Get training, test and validation data generators\n",
    "training_data = tf_records_utils.get_tf_record_ds(data_config['training'])\\\n",
    "                .map(parse_tf_records, num_parallel_calls=AUTOTUNE) \\\n",
    "                .map(parse_label_from_data, num_parallel_calls=AUTOTUNE) \\\n",
    "                .shuffle(model_fit_config['shuffle_buffer_size']).batch(model_fit_config['batch_size'])\n",
    "training_data = training_data.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "validation_data = tf_records_utils.get_tf_record_ds(data_config['validation']) \\\n",
    "                .map(parse_tf_records, num_parallel_calls=AUTOTUNE) \\\n",
    "                .map(parse_label_from_data, num_parallel_calls=AUTOTUNE) \\\n",
    "                .batch(model_fit_config['batch_size'])\n",
    "validation_data = validation_data.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_data = tf_records_utils.get_tf_record_ds(data_config['test']) \\\n",
    "            .map(parse_tf_records, num_parallel_calls=AUTOTUNE) \\\n",
    "            .map(parse_label_from_data, num_parallel_calls=AUTOTUNE) \\\n",
    "            .batch(model_fit_config['batch_size'])\n",
    "test_data = test_data.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "if run_local:\n",
    "    # For testing purposes: Selects just 1 batch of data for training, validation and test\n",
    "    training_data = training_data.take(10)\n",
    "    validation_data = validation_data.take(10)\n",
    "    test_data = test_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "\n",
    "num_epochs = model_fit_config['epochs']\n",
    "\n",
    "# Create Model-DB Instance\n",
    "modeldb_expt_run = modeldb_tf_utilities.create_modeldb_experiment_run(modeldb_config)\n",
    "\n",
    "# Get callbacks and save paths\n",
    "model_data_path_prefix = os.path.join(model_data_path_prefix, modeldb_expt_run.name)\n",
    "callbacks = modeldb_tf_utilities.get_tf_callbacks(modeldb_expt_run, model_data_path_prefix)\n",
    "\n",
    "# Save some attributes before training starts\n",
    "log_model_attributes(modeldb_expt_run)\n",
    "\n",
    "# Define model \n",
    "#loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "loss=tf.keras.losses.MeanSquaredError()\n",
    "optimizer=tf.optimizers.Adam(learning_rate=model_fit_config['initial_lr'])\n",
    "\n",
    "# Create a distribution strategy to run on multiple GPUs\n",
    "if use_distributed_training:\n",
    "    with mirrored_strategy.scope():\n",
    "        sort_model = model_utilities.get_tfrecord_sort_model(feature_normalizer, \n",
    "                                                       numeric_columns_to_norm, \n",
    "                                                       numeric_columns_remaining, \n",
    "                                                       categorical_columns,\n",
    "                                                       categorical_columns_vocabulary_list,\n",
    "                                                       vector_features,\n",
    "                                                        vector_column_lengths)\n",
    "        sort_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "else:\n",
    "    sort_model = model_utilities.get_tfrecord_sort_model(feature_normalizer,\n",
    "                                                   numeric_columns_to_norm, \n",
    "                                                   numeric_columns_remaining, \n",
    "                                                   categorical_columns,\n",
    "                                                   categorical_columns_vocabulary_list,\n",
    "                                                    vector_features,\n",
    "                                                    vector_column_lengths)\n",
    "    sort_model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "log_model_summary(modeldb_expt_run, sort_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "# Start the training process\n",
    "try:\n",
    "    start_time = time.time()  \n",
    "    #cached_ds = training_data.cache()\n",
    "    #cached_validation_ds = validation_data.cache()\n",
    "    # Fit the model\n",
    "    model_history = sort_model.fit(training_data, validation_data=validation_data, epochs=num_epochs, callbacks=callbacks)\n",
    "    # Log time taken to fit model\n",
    "    modeldb_expt_run.log_metric('model_fit_run_duration_in_secs', (time.time() - start_time))            \n",
    "    # Save Model\n",
    "    model_save_path = os.path.join(model_data_path_prefix, 'saved_model/')\n",
    "    sort_model.save(model_save_path)\n",
    "    # But reload model from checkpoint (lowest validation loss) to generate validation performance\n",
    "    model_checkpoint_path = os.path.join(model_data_path_prefix, 'checkpoints/')\n",
    "    if use_checkpointed_model:\n",
    "        # But reload model from checkpoint (lowest validation loss) to generate validation performance        \n",
    "        sort_model.load_weights(model_checkpoint_path)    \n",
    "    # Log other metrics from model including validation data performance\n",
    "    log_model_metrics(modeldb_expt_run, sort_model, model_save_path, model_checkpoint_path, validation_data)\n",
    "    modeldb_expt_run.log_tag('success')\n",
    "except:\n",
    "    modeldb_expt_run.log_tag('failed_run')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a custom/trainer/task.py\n",
    "modeldb_expt_run.log_metric('experiment_run_duration_in_secs', (time.time() - start_time))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the final Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom/\n",
      "custom/requirements.txt\n",
      "custom/setup.py\n",
      "custom/README.md\n",
      "custom/setup.cfg\n",
      "custom/PKG-INFO\n",
      "custom/trainer/\n",
      "custom/trainer/tf_records_utils.py\n",
      "custom/trainer/text_based_tfrecord_config.yaml\n",
      "custom/trainer/modeldb_tf_utilities.py\n",
      "custom/trainer/model_utilities.py\n",
      "custom/trainer/task.py\n",
      "custom/trainer/__init__.py\n",
      "custom/trainer/common_utilities.py\n"
     ]
    }
   ],
   "source": [
    "! rm -f custom.tar custom.tar.gz\n",
    "! tar cvf custom.tar --exclude=\"*.ipynb_checkpoints*\" custom \n",
    "! gzip custom.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://custom.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  9.0 KiB/  9.0 KiB]                                                \n",
      "Operation completed over 1 objects/9.0 KiB.                                      \n",
      "gs://zulilymodeltraining/rmenon/p13n-tf-trainer_module/custom\n"
     ]
    }
   ],
   "source": [
    "! gsutil cp custom.tar.gz $MODULE_PATH/custom.tar.gz\n",
    "! echo $MODULE_PATH/custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-63-af52cae17cef>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-63-af52cae17cef>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    errout. Below does not need to be done always\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "errout. Below does not need to be done always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute this file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Install the built package to test the code locally\n",
    "!pip install custom.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the notebook image to capture the base image of notebook in ModelDB\n",
    "import subprocess\n",
    "notebook_name = subprocess.run(['cat', '/etc/hostname'], stdout=subprocess.PIPE)\n",
    "notebook_name = notebook_name.stdout.decode('utf-8').strip(\"\\n\")\n",
    "runner_docker_image = subprocess.run(['kubectl', 'get', 'po',  notebook_name,  '-o=jsonpath=\"{$.spec.containers[:1].image}\"'], stdout=subprocess.PIPE)\n",
    "runner_docker_image = runner_docker_image.stdout.decode(\"utf-8\").strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m trainer.task --namespace $NAMESPACE \\\n",
    "--modeldb-experiment-name $NAMESPACE-keras-model-local-run-sampled-data \\\n",
    "--modeldb-experiment-run-name keras-with-sampled-data-on-cpu --lr 0.3 --batch-size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once tested uninstall the custom package \n",
    "! pip uninstall trainer --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
